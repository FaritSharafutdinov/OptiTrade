import pandas as pd
import pandas_ta as ta
import numpy as np
import ccxt
import time
from datetime import datetime, timedelta
import requests
import yfinance as yf
import os

# ==============================================================================
# üöÄ –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ==============================================================================
# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
EXCHANGE_ID = 'binance'
SYMBOL = 'BTC/USDT'
TIMEFRAME = '1h'
YEARS_TO_FETCH = 2
SP500_TICKER = 'ES=F'
SP500_INTERVAL = '1h'
OI_SYMBOL_BYBIT = 'BTCUSDT'
OI_CATEGORY_BYBIT = 'linear'
OI_INTERVAL_BYBIT = '1h'
BASE_URL_BYBIT = "https://api.bybit.com"
ENDPOINT_OI_BYBIT = "/v5/market/open-interest"

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ (–≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –¥–ª—è Feature Engineering)
INPUT_FILENAME = f"{SYMBOL.replace('/', '_')}_SP500_OI_{TIMEFRAME}_{YEARS_TO_FETCH}Y.csv"
OUTPUT_FILENAME = 'BTC_USDT_OI_SP500_FEATURES_1h_2Y.csv'

# –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è Feature Engineering
COL_MAPPING = {
    'Open': 'BTC_Open',
    'High': 'BTC_High',
    'Low': 'BTC_Low',
    'Close': 'BTC_Close',
    'Volume': 'BTC_Volume',
    'SP500_Close': 'SP500_Close'
}

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ü–∞–π–ø–ª–∞–π–Ω–∞ ---
# –°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –±–∞—Ä–æ–≤ –Ω—É–∂–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å, —á—Ç–æ–±—ã –ø–æ–∫—Ä—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
# (–æ–∫–Ω–æ Z-score = 100) + –∑–∞–ø–∞—Å –Ω–∞ –ø–µ—Ä–µ—Å—á–µ—Ç. 
# 200 —á–∞—Å–æ–≤ –ø–æ–∫—Ä—ã–≤–∞–µ—Ç 100-—á–∞—Å–æ–≤–æ–µ –æ–∫–Ω–æ.
BARS_TO_FETCH_FOR_UPDATE = 200 
DB_PATH = OUTPUT_FILENAME 
# ==============================================================================


# ==============================================================================
# üõ†Ô∏è –§–£–ù–ö–¶–ò–ò –°–ë–û–†–ê –î–ê–ù–ù–´–• (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô –í –õ–û–ì–ò–ö–ï)
# ==============================================================================

def fetch_ohlcv_data(exchange_id, symbol, timeframe, start_date):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ OHLCV —Å –ø–æ–º–æ—â—å—é ccxt, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—è –ø–∞–≥–∏–Ω–∞—Ü–∏—é.
    (–î–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è —Å–±–æ—Ä–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N –±–∞—Ä–æ–≤)
    """
    try:
        exchange_class = getattr(ccxt, exchange_id)
        exchange = exchange_class({'enableRateLimit': True})
    except AttributeError:
        print(f"‚ùå –ë–∏—Ä–∂–∞ {exchange_id} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è ccxt.")
        return []

    since = int(start_date.timestamp() * 1000)
    all_ohlcv = []
    limit = 1000 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç –¥–ª—è ccxt

    print(f"\n--- 1. –°–±–æ—Ä OHLCV ---")
    print(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∏—Ä–∂–µ: {exchange_id.upper()}")
    
    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –≤—ã–≤–æ–¥, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–æ—Ä–æ—Ç–∫–∏–π —Å–±–æ—Ä
    fetch_range = datetime.utcnow().replace(minute=0, second=0, microsecond=0) - start_date
    range_str = f"{fetch_range.days} –¥–Ω–µ–π" if fetch_range.days > 0 else f"{fetch_range.seconds // 3600} —á–∞—Å–æ–≤"
    print(f"–°–±–æ—Ä —á–∞—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {range_str} –Ω–∞—á–∏–Ω–∞—è —Å {start_date.strftime('%Y-%m-%d %H:%M:%S')}")

    # –õ–æ–≥–∏–∫–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏ –æ—Å—Ç–∞–µ—Ç—Å—è –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —Å start_date
    while True:
        try:
            ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=since, limit=limit)

            if not ohlcv:
                print("–î–∞–Ω–Ω—ã–µ OHLCV –±–æ–ª—å—à–µ –Ω–µ –ø–æ—Å—Ç—É–ø–∞—é—Ç. –°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
                break

            all_ohlcv.extend(ohlcv)

            since = ohlcv[-1][0] + 1

            next_date = datetime.fromtimestamp(since / 1000)
            print(f"–°–æ–±—Ä–∞–Ω–æ {len(all_ohlcv)} —Å–≤–µ—á–µ–π. –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Å {next_date.strftime('%Y-%m-%d %H:%M:%S')}...")
            
            time.sleep(exchange.rateLimit / 1000.0) 

        except ccxt.DDoSProtection as e:
            print(f"üö® –ó–∞—â–∏—Ç–∞ –æ—Ç DDoS: {e}. –û–∂–∏–¥–∞–Ω–∏–µ 10 —Å–µ–∫—É–Ω–¥...")
            time.sleep(10)
        except ccxt.ExchangeNotAvailable as e:
            print(f"‚ùå –ë–∏—Ä–∂–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            break
        except Exception as e:
            print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ OHLCV: {e}. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            break

    return all_ohlcv

def fetch_open_interest_data(symbol, category, interval, start_date):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ Open Interest —Å Bybit API (v5).
    """

    url = BASE_URL_BYBIT + ENDPOINT_OI_BYBIT
    start_ts = int(start_date.timestamp() * 1000)

    all_oi_data = [] 
    limit = 200
    current_cursor = None
    previous_cursor = None

    print(f"\n--- 2. –°–±–æ—Ä Open Interest ---")
    fetch_range = datetime.utcnow().replace(minute=0, second=0, microsecond=0) - start_date
    range_str = f"{fetch_range.days} –¥–Ω–µ–π" if fetch_range.days > 0 else f"{fetch_range.seconds // 3600} —á–∞—Å–æ–≤"
    print(f"–°–±–æ—Ä —á–∞—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ {range_str} –Ω–∞—á–∏–Ω–∞—è —Å {start_date.strftime('%Y-%m-%d %H:%M:%S')}")

    while True:
        params = {
            "category": category,
            "symbol": symbol,
            "intervalTime": interval,
            "limit": limit,
        }
        if current_cursor:
            params['cursor'] = current_cursor

        try:
            response = requests.get(url, params=params)
            response.raise_for_status()
            data = response.json()

            if data.get('retCode') != 0:
                 print(f"‚ùå –û—à–∏–±–∫–∞ API Bybit: {data.get('retMsg', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
                 break

            result = data.get('result', {})
            oi_list = result.get('list', [])

            if not oi_list:
                print("–î–∞–Ω–Ω—ã–µ Open Interest –±–æ–ª—å—à–µ –Ω–µ –ø–æ—Å—Ç—É–ø–∞—é—Ç. –°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
                break

            previous_cursor = current_cursor
            current_cursor = result.get('nextPageCursor')

            if current_cursor == previous_cursor and all_oi_data:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞–≥–∏–Ω–∞—Ü–∏–∏: –ö—É—Ä—Å–æ—Ä –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–±–æ—Ä–∞.")
                break

            current_oldest_ts = int(oi_list[-1]['timestamp'])
            
            # –õ–æ–≥–∏–∫–∞ Bybit API: –∫—É—Ä—Å–æ—Ä –¥–≤–∏–∂–µ—Ç—Å—è –Ω–∞–∑–∞–¥ –ø–æ –≤—Ä–µ–º–µ–Ω–∏. 
            # –ú—ã —Å–æ–±–∏—Ä–∞–µ–º –∏ –ø–µ—Ä–µ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º, –ø–æ–∫–∞ –Ω–µ –¥–æ—Å—Ç–∏–≥–Ω–µ–º start_ts.
            oi_list.reverse()
            all_oi_data.extend(oi_list)

            if current_oldest_ts < start_ts:
                 print("‚úÖ –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –∏–ª–∏ –ø—Ä–æ–π–¥–µ–Ω–∞ –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ —Å–±–æ—Ä–∞. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–±–æ—Ä–∞.")
                 break

            if not current_cursor:
                print("–ö—É—Ä—Å–æ—Ä –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—É—Å—Ç. –°–±–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
                break

            time.sleep(0.5) 

        except Exception as e:
            print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ Bybit: {e}. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            break

    if all_oi_data:
        all_oi_data.sort(key=lambda x: int(x['timestamp']))
        df_oi = pd.DataFrame(all_oi_data)
        df_oi['timestamp'] = pd.to_numeric(df_oi['timestamp'])
        df_oi = df_oi[df_oi['timestamp'] >= start_ts]
        df_oi.drop_duplicates(subset=['timestamp'], keep='first', inplace=True)
        return df_oi

    return pd.DataFrame()


def fetch_sp500_data(ticker, interval, start_date):
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ OHLCV S&P 500 (–∏–ª–∏ –¥—Ä—É–≥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞) —Å Yahoo Finance.
    """
    print(f"\n--- 3. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö S&P 500 ---")

    try:
        # yfinance –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ 'YYYY-MM-DD'
        start_date_str = start_date.strftime('%Y-%m-%d')
        df_sp500 = yf.download(
            ticker,
            start=start_date_str,
            interval=interval,
            progress=False,
        )

        if df_sp500.empty:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {ticker} –∏–ª–∏ DataFrame –ø—É—Å—Ç.")
            return pd.DataFrame()

        # –û—á–∏—Å—Ç–∫–∞ –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫
        if isinstance(df_sp500.columns, pd.MultiIndex):
            df_sp500.columns = [f'{col[0]}_{col[1]}' if col[0] else col[1] for col in df_sp500.columns]
        
        if 'Adj Close' in df_sp500.columns:
            df_sp500.drop(columns=['Adj Close'], inplace=True)
            
        df_sp500.index.name = 'timestamp'
        df_sp500 = df_sp500.tz_localize(None) 
        
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–æ–±—Ä–∞–Ω–æ {len(df_sp500)} —Å–≤–µ—á–µ–π S&P 500.")
        return df_sp500

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–±–æ—Ä–µ S&P 500: {e}")
        return pd.DataFrame()


# ==============================================================================
# üß© –õ–û–ì–ò–ö–ê –û–ë–™–ï–î–ò–ù–ï–ù–ò–Ø –î–ê–ù–ù–´–• (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô –í –õ–û–ì–ò–ö–ï)
# ==============================================================================

def merge_all_data(ohlcv_data, df_oi, df_sp500, sp500_ticker):
    """
    –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–µ DataFrame.
    """
    if not ohlcv_data:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ OHLCV.")
        return None
    
    # 1. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ OHLCV –≤ DataFrame
    df_ohlcv = pd.DataFrame(ohlcv_data, columns=['timestamp', 'Open', 'High', 'Low', 'Close', 'Volume'])
    df_ohlcv['timestamp'] = pd.to_datetime(df_ohlcv['timestamp'], unit='ms')
    df_ohlcv.set_index('timestamp', inplace=True)
    df_ohlcv = df_ohlcv[~df_ohlcv.index.duplicated(keep='first')]
    final_df = df_ohlcv
    
    # 2. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Open Interest
    if not df_oi.empty:
        df_oi['timestamp'] = pd.to_datetime(df_oi['timestamp'], unit='ms')
        df_oi.set_index('timestamp', inplace=True)
        final_df = final_df.join(df_oi[['openInterest']].rename(
            columns={'openInterest': 'Open_Interest'}), how='left')
    
    # 3. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å S&P 500
    if not df_sp500.empty:
        final_df = final_df.join(df_sp500, how='left')

        # --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–æ–ø—É—Å–∫–æ–≤ S&P 500 ---
        # –í—ã–±–∏—Ä–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏ S&P 500 –∏ –∫–æ–ª–æ–Ω–∫–∏ BTC
        sp500_columns = [col for col in final_df.columns if sp500_ticker in str(col) or str(col) in ['Open', 'High', 'Low', 'Close', 'Volume']]

        # ffill –∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω—É–ª—è–º–∏.
        final_df[sp500_columns] = final_df[sp500_columns].ffill()
        final_df[sp500_columns] = final_df[sp500_columns].fillna(0)

        # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–æ–∫, –≥–¥–µ S&P 500 –±—ã–ª —Ä–∞–≤–µ–Ω 0 (–∞–∫—Ç—É–∞–ª—å–Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –±—ç–∫—Ñ–∏–ª–ª–∞)
        is_sp500_zero = (final_df[['Close', 'High', 'Low', 'Open']].eq(0)).all(axis=1) # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ OHLCV
        if False in is_sp500_zero.values:
            first_valid_row_index = is_sp500_zero.idxmin()
            rows_before = final_df.index.get_loc(first_valid_row_index)
            rows_to_drop = final_df.iloc[:rows_before]
            final_df = final_df.drop(rows_to_drop.index, axis=0)

    # 4. –§–∏–Ω–∞–ª—å–Ω–æ–µ –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –°—Ç–æ–ª–±—Ü–æ–≤
    btc_rename_map = {
        'Open': 'BTC_Open',
        'High': 'BTC_High',
        'Low': 'BTC_Low',
        'Close': 'BTC_Close',
        'Volume': 'BTC_Volume'
    }
    final_df.rename(columns=btc_rename_map, inplace=True)

    new_column_names = {}
    yfinance_prefix = "SP500_"

    for col in final_df.columns:
        col_str = str(col)
        
        if SP500_TICKER in col_str:
            if 'Close' in col_str:
                new_name = f"{yfinance_prefix}Close"
            elif 'Open' in col_str:
                new_name = f"{yfinance_prefix}Open"
            elif 'High' in col_str:
                new_name = f"{yfinance_prefix}High"
            elif 'Low' in col_str:
                new_name = f"{yfinance_prefix}Low"
            elif 'Volume' in col_str:
                new_name = f"{yfinance_prefix}Volume"
            else:
                new_name = col_str
            new_column_names[col] = new_name

    final_df.rename(columns=new_column_names, inplace=True)
    return final_df

# ==============================================================================
# üìä –§–£–ù–ö–¶–ò–ò FEATURE ENGINEERING (–ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô –í –õ–û–ì–ò–ö–ï)
# ==============================================================================

def calculate_log_return(series, periods=1):
    """
    –†–∞—Å—á–µ—Ç –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–æ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞.
    """
    return np.log(series / series.shift(periods))

def create_advanced_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    –°–æ–∑–¥–∞–µ—Ç —Å—Ç–∞—Ü–∏–æ–Ω–∞—Ä–Ω—ã–µ —Ñ–∏—á–∏, –≤–∫–ª—é—á–∞—è SP500 log return,
    –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –±–µ–∑ look-ahead bias.
    """
    df_temp = df.copy()
    
    # 1. –ü–°–ï–í–î–û–ù–ò–ú–´ –î–õ–Ø –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û–°–¢–ò (–¥–ª—è pandas_ta)
    for old_name, new_name in COL_MAPPING.items():
        if new_name in df_temp.columns and old_name not in df_temp.columns:
            df_temp[old_name] = df_temp[new_name]
            
    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ Open –¥–ª—è price_change, –µ—Å–ª–∏ –æ–Ω–æ –µ—â–µ –Ω–µ —Å–æ–∑–¥–∞–Ω–æ
    if 'BTC_Open' in df_temp.columns and 'Open' not in df_temp.columns:
        df_temp['Open'] = df_temp['BTC_Open']

    ## 2. –û–°–ù–û–í–ù–´–ï –§–ò–ß–ò
    df_temp['log_return'] = calculate_log_return(df_temp['Close'])
    df_temp['SP500_log_return'] = calculate_log_return(df_temp['SP500_Close'])
    
    ## 3. –°–¢–ê–¶–ò–û–ù–ê–†–ù–´–ï –¶–ï–ù–û–í–´–ï –ü–†–ï–û–ë–†–ê–ó–û–í–ê–ù–ò–Ø (BTC)
    prev_close = df_temp['Close'].shift(1)
    df_temp['price_range'] = (df_temp['High'] - df_temp['Low']) / prev_close
    df_temp['price_change'] = (df_temp['Close'] - df_temp['Open']) / df_temp['Open']
    df_temp['high_to_prev_close'] = (df_temp['High'] - prev_close) / prev_close
    df_temp['low_to_prev_close'] = (df_temp['Low'] - prev_close) / prev_close

    ## 4. –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ –ò –û–ë–™–ï–ú (–û–∫–Ω–∞ 5, 14, 21, 100)
    for window in [5, 14, 21]:
        df_temp[f'volatility_{window}'] = df_temp['log_return'].rolling(window=window).std()
        df_temp[f'volume_ma_{window}'] = df_temp['Volume'].rolling(window=window).mean()
    vol_mean_100 = df_temp['Volume'].rolling(100).mean()
    vol_std_100 = df_temp['Volume'].rolling(100).std()
    df_temp['volume_zscore'] = (df_temp['Volume'] - vol_mean_100) / vol_std_100


    ## 5. –ë–ï–ó–û–ü–ê–°–ù–´–ï –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ (–ù–∞ –æ—Å–Ω–æ–≤–µ prev_Close)
    df_temp['prev_Close'] = df_temp['Close'].shift(1)
    df_temp['prev_High'] = df_temp['High'].shift(1)
    df_temp['prev_Low'] = df_temp['Low'].shift(1)

    macd_data = df_temp.ta.macd(close='prev_Close', fast=12, slow=26, signal=9)
    if macd_data is not None:
        df_temp['MACD_safe'] = macd_data.iloc[:, 0]
        df_temp['MACDs_safe'] = macd_data.iloc[:, 1]
        df_temp['MACDh_safe'] = macd_data.iloc[:, 2]

    rsi_data = df_temp.ta.rsi(close='prev_Close', length=14)
    if rsi_data is not None:
        df_temp['RSI_safe'] = rsi_data

    atr_data = df_temp.ta.atr(high='prev_High', low='prev_Low', close='prev_Close', length=14)
    if atr_data is not None:
        df_temp['ATR_safe_norm'] = atr_data / df_temp['prev_Close']
    
    df_temp.drop(['prev_Close', 'prev_High', 'prev_Low'], axis=1, inplace=True, errors='ignore')


    ## 6. –í–†–ï–ú–ï–ù–ù–´–ï –§–ò–ß–ò (–¶–ò–ö–õ–ò–ß–ï–°–ö–û–ï –ö–û–î–ò–†–û–í–ê–ù–ò–ï)
    df_temp['hour_sin'] = np.sin(2 * np.pi * df_temp.index.hour / 24)
    df_temp['hour_cos'] = np.cos(2 * np.pi * df_temp.index.hour / 24)
    df_temp['day_sin'] = np.sin(2 * np.pi * df_temp.index.dayofweek / 7)
    df_temp['day_cos'] = np.cos(2 * np.pi * df_temp.index.dayofweek / 7)
    df_temp['month_sin'] = np.sin(2 * np.pi * df_temp.index.month / 12)
    df_temp['month_cos'] = np.cos(2 * np.pi * df_temp.index.month / 12)

    ## 7. –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–ß–ò–°–¢–ö–ê
    cols_to_drop = list(COL_MAPPING.keys()) + list(COL_MAPPING.values())
    cols_to_drop.extend(['Open', 'High', 'Low', 'Close', 'Volume','SP500_High', 'SP500_Low', 'SP500_Open', 'SP500_Volume'])
    
    final_cols_to_drop = set(c for c in cols_to_drop) - set(['Close']) 

    final_df = df_temp.drop(columns=list(final_cols_to_drop), errors='ignore')
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NaN (–ø–æ—è–≤–ª—è—é—Ç—Å—è –∏–∑-–∑–∞ rolling windows –∏ shift)
    final_df.dropna(inplace=True) 

    return final_df

# ==============================================================================
# ‚öôÔ∏è –û–°–ù–û–í–ù–û–ô –ü–ê–ô–ü–õ–ê–ô–ù: –†–ï–ñ–ò–ú–´ –†–ê–ë–û–¢–´
# ==============================================================================

def run_batch_history():
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∑–∞ YEARS_TO_FETCH –∏ —Å–æ–∑–¥–∞–µ—Ç DB_PATH.
    –í—ã–∑—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ.
    """
    print("\n" + "="*70)
    print("ü§ñ –≠–¢–ê–ü: –ü–û–õ–ù–´–ô –ò–°–¢–û–†–ò–ß–ï–°–ö–ò–ô –°–ë–û–† –ò –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï")
    print("="*70)
    
    end_date = datetime.utcnow().replace(minute=0, second=0, microsecond=0)
    start_date = end_date - timedelta(days=364 * YEARS_TO_FETCH)

    try:
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        ohlcv_data = fetch_ohlcv_data(EXCHANGE_ID, SYMBOL, TIMEFRAME, start_date)
        df_oi = fetch_open_interest_data(OI_SYMBOL_BYBIT, OI_CATEGORY_BYBIT, OI_INTERVAL_BYBIT, start_date)
        df_sp500 = fetch_sp500_data(SP500_TICKER, SP500_INTERVAL, start_date)

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞
        df_raw = merge_all_data(ohlcv_data, df_oi, df_sp500, SP500_TICKER)
        
        if df_raw is None or df_raw.empty:
            print("‚ùå Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω —Å –æ—à–∏–±–∫–æ–π: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame –ø—É—Å—Ç.")
            return
            
        print(f"‚úÖ –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã. –†–∞–∑–º–µ—Ä: {len(df_raw)}")

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    # --- 2. FEATURE ENGINEERING ---
    print("\n" + "="*70)
    print("üî¨ –≠–¢–ê–ü 2: –°–û–ó–î–ê–ù–ò–ï –ò–ù–ñ–ï–ù–ï–†–ò–ù–ì–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("="*70)
    
    try:
        df_features = create_advanced_features(df_raw)
        
        # --- 3. –§–ò–ù–ê–õ–¨–ù–´–ô –í–´–í–û–î –ò –°–û–•–†–ê–ù–ï–ù–ò–ï ---
        df_features.to_csv(DB_PATH)
        print(f"‚úÖ –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ —Ñ–∞–π–ª: {DB_PATH}. –†–∞–∑–º–µ—Ä: {len(df_features)}")
        
    except Exception as e:
         print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ Feature Engineering: {e}")

def run_incremental_update():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –µ–∂–µ—á–∞—Å–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Å–≤–µ—á–µ–π, 
    –∏—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É.
    """
    print("\n" + "="*70)
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ü§ñ –≠–¢–ê–ü 1: –°–ë–û–† –ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–•")
    print("="*70)
    
    # 0. –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–û–ï –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –°–¢–ê–†–¢–û–í–û–ô –î–ê–¢–´
    
    # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –¥–∞—Ç–∞ –Ω–∞—á–∞–ª–∞ —Å–±–æ—Ä–∞: 205 —á–∞—Å–æ–≤ –Ω–∞–∑–∞–¥ –æ—Ç —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Å–∞
    end_date = datetime.utcnow().replace(minute=0, second=0, microsecond=0)
    start_date_fetch = end_date - timedelta(hours=BARS_TO_FETCH_FOR_UPDATE + 5) 
    
    if os.path.exists(DB_PATH):
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É, —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π timestamp
            df_old = pd.read_csv(DB_PATH, index_col='timestamp', parse_dates=True)
            
            # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π timestamp –∏ –æ—Ç—Å—Ç—É–ø–∞–µ–º –Ω–∞–∑–∞–¥ –Ω–∞ —Ä–∞–∑–º–µ—Ä –æ–∫–Ω–∞ (200 —á–∞—Å–æ–≤)
            last_timestamp = df_old.index.max()
            fetch_from_date = last_timestamp - timedelta(hours=BARS_TO_FETCH_FOR_UPDATE)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–Ω—É—é –¥–∞—Ç—É, —á—Ç–æ–±—ã –ø–æ–∫—Ä—ã—Ç—å –ø–µ—Ä–µ—Å—á–µ—Ç —Å—Ç–∞—Ä—ã—Ö —Ñ–∏—á–µ–π
            if fetch_from_date > start_date_fetch:
                 start_date_fetch = fetch_from_date

            print(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞–π–¥–µ–Ω–∞. –ü–æ—Å–ª–µ–¥–Ω–∏–π timestamp: {last_timestamp}. –ù–∞—á–∏–Ω–∞–µ–º —Å–±–æ—Ä —Å: {start_date_fetch.strftime('%Y-%m-%d %H:%M:%S')}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –±–∞–∑—ã {DB_PATH}: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–µ—Ñ–æ–ª—Ç–Ω—ã–π start_date_fetch.")
            df_old = None # –°–±—Ä–æ—Å —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏

    # 1. –°–ë–û–† –ò –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï
    try:
        ohlcv_data = fetch_ohlcv_data(EXCHANGE_ID, SYMBOL, TIMEFRAME, start_date_fetch)
        df_oi = fetch_open_interest_data(OI_SYMBOL_BYBIT, OI_CATEGORY_BYBIT, OI_INTERVAL_BYBIT, start_date_fetch)
        df_sp500 = fetch_sp500_data(SP500_TICKER, SP500_INTERVAL, start_date_fetch)

        df_raw_new = merge_all_data(ohlcv_data, df_oi, df_sp500, SP500_TICKER)
        
        if df_raw_new is None or df_raw_new.empty:
            print("‚ùå Pipeline –∑–∞–≤–µ—Ä—à–µ–Ω: –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π DataFrame –ø—É—Å—Ç.")
            return
            
        print(f"‚úÖ –ò—Å—Ö–æ–¥–Ω—ã–µ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ) –¥–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã. –†–∞–∑–º–µ—Ä: {len(df_raw_new)}")

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —ç—Ç–∞–ø–µ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return

    # 2. FEATURE ENGINEERING (–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 200+ –±–∞—Ä–æ–≤)
    print("\n" + "="*70)
    print("üî¨ –≠–¢–ê–ü 2: –°–û–ó–î–ê–ù–ò–ï –ò–ù–ñ–ï–ù–ï–†–ò–ù–ì–û–í–´–• –ü–†–ò–ó–ù–ê–ö–û–í")
    print("="*70)
    
    try:
        df_features_new = create_advanced_features(df_raw_new)
        
        if df_features_new.empty:
            print("‚ö†Ô∏è DataFrame —Ñ–∏—á–µ–π –ø—É—Å—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ NaN. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
            return

    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ Feature Engineering: {e}")
        return

    # 3. –ò–ù–ö–†–ï–ú–ï–ù–¢–ê–õ–¨–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï
    print("\n" + "="*70)
    print("üíæ –≠–¢–ê–ü 3: –û–ë–ù–û–í–õ–ï–ù–ò–ï –ü–û–°–¢–û–Ø–ù–ù–û–ô –ë–ê–ó–´ –î–ê–ù–ù–´–•")
    print("="*70)
    
    if os.path.exists(DB_PATH) and df_old is not None:
        # ‚ö†Ô∏è –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–æ–≤–æ–º DF, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Å—Ç–∞—Ä–æ–º
        new_features_to_append = df_features_new[~df_features_new.index.isin(df_old.index)]
        
        if new_features_to_append.empty:
            print("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∞–∫—Ç—É–∞–ª—å–Ω–∞. –ù–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–µ—Ç.")
            return

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç–∞—Ä—É—é –∏ –Ω–æ–≤—É—é —á–∞—Å—Ç–∏
        final_db = pd.concat([df_old, new_features_to_append])
        final_db.sort_index(inplace=True)
        
        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫: {len(new_features_to_append)}. –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã: {len(final_db)}")
    else:
        # –ï—Å–ª–∏ –±–∞–∑–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (–ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫)
        final_db = df_features_new
        print(f"–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è. –†–∞–∑–º–µ—Ä: {len(final_db)}")

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—å –±–∞–∑—ã)
    final_db.to_csv(DB_PATH)
    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Ñ–∏—á–µ–π —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –≤: {DB_PATH}")
    print("="*70)


if __name__ == '__main__':
    # –ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö: –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—É—é –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫—É—é –±–∞–∑—É (–Ω–∞ 2 –≥–æ–¥–∞).
    # –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ —ç—Ç—É —Å—Ç—Ä–æ–∫—É –Ω—É–∂–Ω–æ –∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å!
    # run_batch_history() 
    
    # –ï–ñ–ï–ß–ê–°–ù–û–ï –û–ë–ù–û–í–õ–ï–ù–ò–ï: –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ cron/–ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–µ.
    run_incremental_update()
